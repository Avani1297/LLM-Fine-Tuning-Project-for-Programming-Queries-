{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2014188a",
   "metadata": {},
   "source": [
    "1. Model and Data decisions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e45aab",
   "metadata": {},
   "source": [
    " a. What data source did you choose and why?\n",
    "- I chose the data source of stackoverflow, which is a stck of all programming related quesiton and asnwers. It is whre people share their errors they are facing while coding and get guidacne by the community. By training the LLM model with this data, we are training the model the can offer relavant ansers to the programming questions asked by the users making it easier for them.\n",
    "  \n",
    "  \n",
    " b. What business/environmental/social/political problem will your fine-tuned model tackle?\n",
    " \n",
    "- The model will overcome the challenge of quicly finding the answers from the sea of programming questions. Where nowadays, the solving problem on time is crucial, this will help aid the process and bring effeciency in software developmnt. It will help troubleshoot the problems swiftly and accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3429c32",
   "metadata": {},
   "source": [
    "2.  Explain to me, in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e5b48",
   "metadata": {},
   "source": [
    " a. What is LoRA, and why is it necessary?\n",
    " \n",
    "- LoRA, organizes the amssive chunks of information that a model uses to make decisons,in a way that lets the model update and adjsut itself without doing much redos.  It works by freezing the ordiginal model weights and decmposing the original matrix into two. With this, training is faster, and effecient in memory.\n",
    " \n",
    " b. What is QLoRA and why is it necessary?\n",
    " \n",
    "- QLoRA  is an extension of LoRA that quantized the model to reduce the precision of model parameters. It is necessary because it significnatly lowers the computational cost while also preseving the eprformance of the model.\n",
    " \n",
    " c. What is instruction fine-tuning and how is it different from the unsupervised\n",
    " pre-training?\n",
    " \n",
    " - Instrcution fine tuning is teaching the model to perform certain tasks in a certain way , like instructing it by giving direct commands.  While, unsupervised learning is not supervising the model and letting it explore on itw own without any direct commands.\n",
    " \n",
    " d. Is what you are doing here considered instruction fine-tuning or unsupervised\n",
    " pre-training? why\n",
    " \n",
    " - What we are doing here is considered instruction fine tuning, because we are taking a pre-trained model and adapting that model to the tasks, which is fine-tuning, we are not training the model from scratch which would be unsupervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "\n",
    "    hf_token: str = field(metadata={\"help\": \"Authentication Token for hugging face\"})\n",
    "\n",
    "\n",
    "    model_name: Optional[str] = field(\n",
    "        default=\"meta-llama/Llama-2-7b-hf\", metadata={\"help\": \"The model name on the hugging face that we are using\"}\n",
    "    )\n",
    "\n",
    "    seed: Optional[int] = field(\n",
    "        default=4761, metadata = {'help':'Random seed to intialize'}\n",
    "    )\n",
    "\n",
    "    data_path: Optional[str] = field(\n",
    "        default=\"./data/forums_short.json\", metadata={\"help\": \"The path of the data that we are using to fine tune the llm\"}\n",
    "    )\n",
    "\n",
    "    output_dir: Optional[str] = field(\n",
    "        default=\"output\", metadata={\"help\": \"the path of the output directory where we want to save the fine-tuned outputs\"}\n",
    "    )\n",
    "    \n",
    "    per_device_train_batch_size: Optional[int] = field(\n",
    "        default = 2, metadata = {\"help\":\"Numbe rof training samples processed on each GPU per step\"}\n",
    "    )\n",
    "\n",
    "    gradient_accumulation_steps: Optional[int] = field(\n",
    "        default = 1, metadata = {\"help\":\"Numbe rof training steps to accumulate gradient before a backward/upward pass \"}\n",
    "    )\n",
    "\n",
    "    optim: Optional[str] = field(\n",
    "        default = \"paged_adamw_32bit\", metadata = {\"help\":\"Selecting which optimizer to usefor the fine tuning\"}\n",
    "    )\n",
    "\n",
    "    save_steps: Optional[int] = field(\n",
    "        default = 25, metadata = {\"help\":\"Number of trianing steps before saving the progress on the model\"}\n",
    "    )\n",
    "\n",
    "    logging_steps: Optional[int] = field(\n",
    "        default = 1, metadata = {\"help\":\"How often to get progres sof the model's training\"}\n",
    "    )\n",
    "\n",
    "    learning_rate: Optional[float] = field(\n",
    "        default = 2e-4, metadata = {\"help\":\"The initisl rate at which the model will learn,\"}\n",
    "    )\n",
    "\n",
    "    max_grad_norm: Optional[float] = field (\n",
    "        default = 0.3, metadata = {\"help\":\"Max threshold to prevent the model's learning to go off track\"}\n",
    "    )\n",
    "\n",
    "    num_train_epochs: Optional[int] = field (\n",
    "        default = 1, metadata = {\"help\":\"Number of times the training dataset will go throughthe entire dataset\"}\n",
    "    ) \n",
    "\n",
    "    warmup_ratio: Optional[float] = field (\n",
    "        default = 0.03, metadata = {\"help\":\"Numbe rof steps used for a linear warmup of the training model\"}\n",
    "    )\n",
    "\n",
    "    lr_scheduler_type: Optional[str] = field(\n",
    "        default=\"cosine\", metadata = {\"help\":\"Adjusts the learning rate as training progresses, how model learns over time\"}\n",
    "    ) \n",
    "\n",
    "    lora_dir: Optional[str] = field(default = \"./model/llm_hate_speech_lora\", metadata = {\"help\":\"Directory where LoRA is saved\"})\n",
    "\n",
    "    max_steps: Optional[int] = field(default=-1, metadata={\"help\": \"The total number of training set to be perofrmed, if positive\"})\n",
    "\n",
    "    text_field: Optional[str] = field(default='chat_sample', metadata={\"help\": \"Default name of the data field that contains the text that has been used to train the model\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216876bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "\n",
    "#Access tools from hugging face's library \n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer,\n",
    "    set_seed,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "from huggingface_hub import login, HfFolder\n",
    "from trl import SFTTrainer\n",
    "from utils import print_trainable_parameters, find_all_linear_names\n",
    "from train_args import ScriptArguments\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\n",
    "\n",
    "#Setting up a parser to read and write cmd line args\n",
    "parser = HfArgumentParser(ScriptArguments)\n",
    "args = parser.parse_args_into_dataclasses()[0]\n",
    "\n",
    "#Training the model with the hyper-paremeters initalized above\n",
    "def training_function(args):\n",
    "    \n",
    "    login(token=args.hf_token) #login using the authenticaion token\n",
    "\n",
    "    set_seed(args.seed) #Setting a random seed\n",
    "\n",
    "    data_path=args.data_path #path to the training data\n",
    "\n",
    "    dataset = load_dataset(data_path) #loading the dataset with the given path\n",
    "    \n",
    "    #Configuring bits and bytes\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    #Loading a pre-trained model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_name,\n",
    "        use_cache=False,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    #Loading the tokenizer and setting the padding token and dorection \n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "    tokenizer.pad_token=tokenizer.eos_token\n",
    "    tokenizer.padding_side='right'\n",
    "    \n",
    "    #Prepare the model for k-bit training\n",
    "    model=prepare_model_for_kbit_training(model)\n",
    "\n",
    "    #Finding all linear modules within the model\n",
    "    modules=find_all_linear_names(model)\n",
    "    #LoRA cinfiguration\n",
    "    config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias='none',\n",
    "        task_type='CAUSAL_LM',\n",
    "        target_modules=modules\n",
    "    )\n",
    "\n",
    "    #Fetchig model with LoRA adjustments\n",
    "    model=get_peft_model(model, config)\n",
    "    output_dir = args.output_dir #Directory to save output\n",
    "    \n",
    "    #Passing all the training arguments for the model\n",
    "    training_arguments = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        optim=args.optim,\n",
    "        save_steps=args.save_steps,\n",
    "        logging_steps=args.logging_steps,\n",
    "        learning_rate=args.learning_rate,\n",
    "        bf16=False,\n",
    "        max_grad_norm=args.max_grad_norm,\n",
    "        num_train_epochs=args.num_train_epochs,\n",
    "        warmup_ratio=args.warmup_ratio,\n",
    "        group_by_length=True,\n",
    "        lr_scheduler_type=args.lr_scheduler_type,\n",
    "        tf32=False,\n",
    "        report_to=\"none\",\n",
    "        push_to_hub=False,\n",
    "        max_steps = args.max_steps\n",
    "    )\n",
    "    #Initlaizgin trainer for sparse fine tuning\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset['train'],\n",
    "        dataset_text_field=args.text_field,\n",
    "        max_seq_length=2048,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments\n",
    "    )\n",
    "    \n",
    "    #Setting data nomrlaizers to use 32-bit precision\n",
    "    for name, module in trainer.model.named_modules():\n",
    "        if \"norm\" in name:\n",
    "            module = module.to(torch.float32)\n",
    "\n",
    "    print('starting training')\n",
    "\n",
    "    #Startnig the training\n",
    "    trainer.train()\n",
    "\n",
    "    print('LoRA training complete')\n",
    "    lora_dir = args.lora_dir #Directory to save the LoRA adapted model\n",
    "    trainer.model.push_to_hub(lora_dir, safe_serialization=False) #Pushing the model to Hugging face hub\n",
    "    \n",
    "    print(\"saved lora adapters\")\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    training_function(args) #Start the training if the script is executed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    set_seed,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from huggingface_hub import login, HfFolder\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# COPIED FROM https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    trainable_params /= 2\n",
    "    print(\n",
    "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "#Formatting a prommpt to ask the model\n",
    "def format_prompt(eval_str):\n",
    "    prompt=f\"\"\"###User: Categorize the following statement as offensive, neutral, or hateful: \\n\\n'{eval_str}'\\n\n",
    "follow this format with your response:\n",
    "\n",
    "(1) Holistic Explanation: Provide a brief explanation (up to 150 words) on why the statement falls into the chosen category. If neutral, explain why it's neutral. If it's offensive or hateful, summarize the harmful impact,  detailing its impact on each group mentioned.\n",
    "\n",
    "Classification: (neutral, offensive, hate)\n",
    "\n",
    "If the statement is categorized as offensive or hateful, also include the following:\n",
    "\n",
    "(2) Affected Groups: List the group(s) most harmed by the statement.\n",
    "(3) Harmful Words: Identify specific harmful word(s) or phrase(s) directed at each group.\n",
    "(4) Reason for Harm: Briefly explain why the words are hurtful to each group.\n",
    "\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "#Neural network class with 1 hidden layer and an output layer, with ReLU activation in between\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(384, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "     #Forward pass of nueral net   \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# COPIED FROM https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "# Fiding and listing all the names of linear modules in amodel\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
